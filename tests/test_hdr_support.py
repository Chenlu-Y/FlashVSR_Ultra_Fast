#!/usr/bin/env python3
"""
æµ‹è¯• FlashVSR æ¨¡å‹æ˜¯å¦æ”¯æŒ HDR èŒƒå›´ï¼ˆå€¼ > 1ï¼‰

æ£€æŸ¥ç‚¹ï¼š
1. è¾“å…¥å¤„ç†ï¼šprepare_input_tensor æ˜¯å¦ä¿ç•™ > 1 çš„å€¼
2. æ¨¡å‹å†…éƒ¨ï¼šæ˜¯å¦æœ‰ clamp é™åˆ¶
3. VAE è¾“å‡ºï¼šæ˜¯å¦é™åˆ¶åœ¨ [-1, 1]
4. æœ€ç»ˆè¾“å‡ºï¼šæ˜¯å¦è¢« clip åˆ° [0, 1]
"""

import os
import sys
import re

# å°è¯•å¯¼å…¥ torch å’Œ numpyï¼ˆå¯é€‰ï¼‰
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸  torch æœªå®‰è£…ï¼Œå°†è·³è¿‡éœ€è¦ torch çš„æµ‹è¯•")

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    print("âš ï¸  numpy æœªå®‰è£…ï¼Œå°†è·³è¿‡éœ€è¦ numpy çš„æµ‹è¯•")

# æ·»åŠ é¡¹ç›®è·¯å¾„
_project_root = os.path.dirname(os.path.abspath(__file__))
if _project_root not in sys.path:
    sys.path.insert(0, _project_root)

print("=" * 80)
print("FlashVSR HDR æ”¯æŒæµ‹è¯•")
print("=" * 80)

# ============================================================================
# æµ‹è¯• 1: æ£€æŸ¥ prepare_input_tensor çš„è¡Œä¸º
# ============================================================================
print("\n[æµ‹è¯• 1] æ£€æŸ¥ prepare_input_tensor çš„æ•°å€¼èŒƒå›´è½¬æ¢")
print("-" * 80)

if TORCH_AVAILABLE and NUMPY_AVAILABLE:
    # åˆ›å»ºåŒ…å« HDR å€¼çš„æµ‹è¯•å¼ é‡ï¼ˆæ¨¡æ‹Ÿ HDR çº¿æ€§å€¼ï¼Œå¯èƒ½ > 1ï¼‰
    # æ ¼å¼: (N, H, W, C) = (1, 4, 4, 3)
    hdr_values = np.array([
        [[0.0, 0.5, 1.0],   # SDR èŒƒå›´
         [1.5, 2.0, 3.0],   # HDR èŒƒå›´ï¼ˆ> 1ï¼‰
         [5.0, 10.0, 0.8],  # é«˜ HDR å€¼
         [0.2, 1.2, 2.5]]   # æ··åˆ
    ], dtype=np.float32)

    # æ‰©å±•åˆ°å®Œæ•´çš„ (1, 4, 4, 3) å¼ é‡
    hdr_tensor = torch.from_numpy(np.tile(hdr_values, (1, 1, 1, 1))).float()
    print(f"åŸå§‹è¾“å…¥èŒƒå›´: [{hdr_tensor.min():.4f}, {hdr_tensor.max():.4f}]")
    print(f"åŸå§‹è¾“å…¥åŒ…å« > 1 çš„å€¼: {(hdr_tensor > 1.0).any().item()}")

    # æ¨¡æ‹Ÿ prepare_input_tensor çš„è½¬æ¢ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸åŒ…å« upscaleï¼‰
    test_tensor = hdr_tensor * 2.0 - 1.0
    print(f"ç»è¿‡ * 2.0 - 1.0 å: [{test_tensor.min():.4f}, {test_tensor.max():.4f}]")
    print(f"æ˜¯å¦è¶…å‡º [-1, 1]: {(test_tensor < -1.0).any().item() or (test_tensor > 1.0).any().item()}")

    # æ£€æŸ¥ clamp åçš„æ•ˆæœ
    clamped = torch.clamp(test_tensor, -1.0, 1.0)
    print(f"clamp(-1, 1) å: [{clamped.min():.4f}, {clamped.max():.4f}]")
    print(f"ä¿¡æ¯ä¸¢å¤±: {((test_tensor != clamped) & (test_tensor.abs() > 1.0)).any().item()}")
else:
    print("âš ï¸  è·³è¿‡ï¼ˆéœ€è¦ torch å’Œ numpyï¼‰")
    print("  ç†è®ºåˆ†æ: è¾“å…¥ [0, 1] â†’ * 2.0 - 1.0 â†’ [-1, 1]")
    print("  å¦‚æœè¾“å…¥ > 1ï¼Œè½¬æ¢åä¼šè¶…å‡º [-1, 1]ï¼Œç„¶åè¢« clamp æˆªæ–­")

# ============================================================================
# æµ‹è¯• 2: æ£€æŸ¥ VAE è¾“å‡ºèŒƒå›´é™åˆ¶
# ============================================================================
print("\n[æµ‹è¯• 2] æ£€æŸ¥ VAE è¾“å‡ºèŒƒå›´é™åˆ¶ï¼ˆæ¨¡æ‹Ÿï¼‰")
print("-" * 80)

if TORCH_AVAILABLE:
    # æ¨¡æ‹Ÿ VAE å¯èƒ½è¾“å‡ºçš„å€¼ï¼ˆå‡è®¾æ¨¡å‹å†…éƒ¨äº§ç”Ÿäº†è¶…å‡ºèŒƒå›´çš„å€¼ï¼‰
    vae_output = torch.tensor([[[[-2.0, -1.0, 0.0, 1.0, 2.0, 3.0]]]], dtype=torch.float32)
    print(f"VAE åŸå§‹è¾“å‡ºèŒƒå›´: [{vae_output.min():.4f}, {vae_output.max():.4f}]")

    # åº”ç”¨ clamp_(-1, 1)ï¼ˆå¦‚ wan_video_vae.py:785ï¼‰
    vae_clamped = vae_output.clamp_(-1, 1)
    print(f"clamp_(-1, 1) å: [{vae_clamped.min():.4f}, {vae_clamped.max():.4f}]")
    print(f"è¢«æˆªæ–­çš„å€¼æ•°é‡: {(vae_output != vae_clamped).sum().item()}")
else:
    print("âš ï¸  è·³è¿‡ï¼ˆéœ€è¦ torchï¼‰")
    print("  ä»£ç ä½ç½®: src/models/wan_video_vae.py:785")
    print("  return video.clamp_(-1, 1)  # å¼ºåˆ¶é™åˆ¶åœ¨ [-1, 1]")

# ============================================================================
# æµ‹è¯• 3: æ£€æŸ¥æœ€ç»ˆè¾“å‡ºè½¬æ¢
# ============================================================================
print("\n[æµ‹è¯• 3] æ£€æŸ¥æœ€ç»ˆè¾“å‡ºè½¬æ¢ï¼ˆvae_output_to_videoï¼‰")
print("-" * 80)

if TORCH_AVAILABLE:
    # æ¨¡æ‹Ÿ VAE è¾“å‡ºï¼ˆåœ¨ [-1, 1] èŒƒå›´å†…ï¼‰
    vae_out = torch.tensor([[[[-1.0, -0.5, 0.0, 0.5, 1.0]]]], dtype=torch.float32)
    print(f"VAE è¾“å‡ºèŒƒå›´: [{vae_out.min():.4f}, {vae_out.max():.4f}]")

    # è½¬æ¢ä¸º [0, 1]ï¼ˆbase.py:40 çš„é€»è¾‘ï¼‰
    converted = (vae_out / 2 + 0.5)
    print(f"ç»è¿‡ / 2 + 0.5 å: [{converted.min():.4f}, {converted.max():.4f}]")

    # åº”ç”¨ clip(0, 1)
    final = converted.clip(0, 1)
    print(f"clip(0, 1) å: [{final.min():.4f}, {final.max():.4f}]")
    print(f"æ˜¯å¦è¢« clip: {(converted != final).any().item()}")
else:
    print("âš ï¸  è·³è¿‡ï¼ˆéœ€è¦ torchï¼‰")
    print("  ä»£ç ä½ç½®: src/pipelines/base.py:40, 46")
    print("  (image / 2 + 0.5).clip(0, 1)  # ä» [-1, 1] è½¬å› [0, 1]ï¼Œç„¶å clip")

# ============================================================================
# æµ‹è¯• 4: æ£€æŸ¥å®é™…ä»£ç ä¸­çš„ clamp ä½ç½®
# ============================================================================
print("\n[æµ‹è¯• 4] æ£€æŸ¥ä»£ç ä¸­çš„ clamp/clip ä½ç½®")
print("-" * 80)

import re

clamp_locations = []
files_to_check = [
    "src/pipelines/flashvsr_tiny.py",
    "src/pipelines/flashvsr_full.py",
    "src/pipelines/base.py",
    "src/models/wan_video_vae.py",
    "infer_video_distributed.py"
]

for filepath in files_to_check:
    full_path = os.path.join(_project_root, filepath)
    if os.path.exists(full_path):
        with open(full_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for i, line in enumerate(lines, 1):
                if re.search(r'\.clamp|\.clip|torch\.clamp|torch\.clip', line):
                    clamp_locations.append((filepath, i, line.strip()))

print(f"æ‰¾åˆ° {len(clamp_locations)} å¤„ clamp/clip æ“ä½œ:")
for filepath, line_num, code in clamp_locations[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
    print(f"  {filepath}:{line_num} - {code}")
if len(clamp_locations) > 10:
    print(f"  ... è¿˜æœ‰ {len(clamp_locations) - 10} å¤„")

# ============================================================================
# æµ‹è¯• 5: æ¨¡æ‹Ÿå®Œæ•´æµç¨‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
# ============================================================================
print("\n[æµ‹è¯• 5] æ¨¡æ‹Ÿå®Œæ•´æ•°æ®å¤„ç†æµç¨‹")
print("-" * 80)

if TORCH_AVAILABLE:
    # æ¨¡æ‹Ÿä¸€ä¸ªåŒ…å« HDR å€¼çš„è¾“å…¥å¸§
    input_hdr = torch.tensor([[[
        [0.1, 0.5, 1.0],      # SDR
        [1.5, 2.0, 3.0],      # HDR
        [5.0, 0.8, 1.2]       # é«˜ HDR
    ]]], dtype=torch.float32)  # (1, 1, 3, 3)

    print(f"æ­¥éª¤ 0 - åŸå§‹è¾“å…¥: [{input_hdr.min():.4f}, {input_hdr.max():.4f}]")
    print(f"  åŒ…å« > 1 çš„å€¼: {(input_hdr > 1.0).any().item()}")

    # æ­¥éª¤ 1: prepare_input_tensor è½¬æ¢
    step1 = input_hdr * 2.0 - 1.0
    print(f"æ­¥éª¤ 1 - * 2.0 - 1.0: [{step1.min():.4f}, {step1.max():.4f}]")
    print(f"  è¶…å‡º [-1, 1]: {(step1.abs() > 1.0).any().item()}")

    # æ­¥éª¤ 2: æ¨¡å‹å†…éƒ¨å¯èƒ½çš„ clampï¼ˆæ¨¡æ‹Ÿï¼‰
    step2 = torch.clamp(step1, -1.0, 1.0)
    print(f"æ­¥éª¤ 2 - clamp(-1, 1): [{step2.min():.4f}, {step2.max():.4f}]")
    print(f"  ä¿¡æ¯ä¸¢å¤±: {(step1 != step2).any().item()}")

    # æ­¥éª¤ 3: VAE è¾“å‡ºï¼ˆå‡è®¾åœ¨ [-1, 1]ï¼‰
    step3 = step2  # VAE è¾“å‡ºä¹Ÿåœ¨ [-1, 1]
    print(f"æ­¥éª¤ 3 - VAE è¾“å‡º: [{step3.min():.4f}, {step3.max():.4f}]")

    # æ­¥éª¤ 4: è½¬æ¢å› [0, 1]
    step4 = (step3 / 2 + 0.5)
    print(f"æ­¥éª¤ 4 - / 2 + 0.5: [{step4.min():.4f}, {step4.max():.4f}]")

    # æ­¥éª¤ 5: clip(0, 1)
    step5 = step4.clip(0, 1)
    print(f"æ­¥éª¤ 5 - clip(0, 1): [{step5.min():.4f}, {step5.max():.4f}]")

    # è®¡ç®—ä¿¡æ¯ä¸¢å¤±
    original_max = input_hdr.max().item()
    final_max = step5.max().item()
    if original_max > 1.0:
        print(f"\nâš ï¸  ä¿¡æ¯ä¸¢å¤±åˆ†æ:")
        print(f"  åŸå§‹æœ€å¤§å€¼: {original_max:.4f}")
        print(f"  æœ€ç»ˆæœ€å¤§å€¼: {final_max:.4f}")
        print(f"  ä¸¢å¤±æ¯”ä¾‹: {(1.0 - final_max / original_max) * 100:.2f}%")
        print(f"  ç»“è®º: HDR ä¿¡æ¯ï¼ˆ> 1 çš„å€¼ï¼‰è¢«å®Œå…¨ä¸¢å¤±")
else:
    print("âš ï¸  è·³è¿‡ï¼ˆéœ€è¦ torchï¼‰")
    print("  ç†è®ºæµç¨‹:")
    print("    è¾“å…¥ HDR [0, 5] â†’ * 2.0 - 1.0 â†’ [-1, 9]")
    print("    â†’ clamp(-1, 1) â†’ [-1, 1] (ä¸¢å¤± > 1 çš„ä¿¡æ¯)")
    print("    â†’ VAE å¤„ç† â†’ [-1, 1]")
    print("    â†’ / 2 + 0.5 â†’ [0, 1]")
    print("    â†’ clip(0, 1) â†’ [0, 1]")
    print("  ç»“æœ: æ‰€æœ‰ > 1 çš„ HDR å€¼éƒ½è¢«æˆªæ–­åˆ° 1.0")

# ============================================================================
# æ€»ç»“
# ============================================================================
print("\n" + "=" * 80)
print("æµ‹è¯•æ€»ç»“")
print("=" * 80)

print("\nâœ… æ£€æŸ¥é¡¹:")
print("  1. prepare_input_tensor: ä¼šå°† [0, 1] è½¬æ¢åˆ° [-1, 1]")
print("  2. æ¨¡å‹å†…éƒ¨: æœ‰ clamp(-1, 1) é™åˆ¶")
print("  3. VAE è¾“å‡º: æœ‰ clamp_(-1, 1) é™åˆ¶")
print("  4. æœ€ç»ˆè¾“å‡º: æœ‰ clip(0, 1) é™åˆ¶")

print("\nâŒ ç»“è®º:")
print("  æ¨¡å‹ä¸æ”¯æŒ HDR èŒƒå›´ï¼ˆå€¼ > 1ï¼‰")
print("  æ‰€æœ‰ HDR ä¿¡æ¯åœ¨è¾“å…¥å¤„ç†é˜¶æ®µå°±è¢«å½’ä¸€åŒ–/æˆªæ–­")

print("\nğŸ’¡ å»ºè®®:")
print("  å¦‚æœè¦æ”¯æŒ HDRï¼Œéœ€è¦:")
print("  1. æ–¹æ¡ˆ A: å½’ä¸€åŒ–æ–¹æ¡ˆï¼ˆæ¨èï¼‰")
print("     - è¾“å…¥æ—¶è®°å½•æœ€å¤§å€¼ï¼Œå½’ä¸€åŒ–åˆ° [-1, 1]")
print("     - è¾“å‡ºæ—¶åå½’ä¸€åŒ–å›åŸå§‹ HDR èŒƒå›´")
print("  2. æ–¹æ¡ˆ B: å¯¹æ•°ç©ºé—´è½¬æ¢")
print("     - è¾“å…¥: log(1 + hdr_value)")
print("     - è¾“å‡º: exp(output) - 1")
print("  3. æ–¹æ¡ˆ C: ä¿®æ”¹æ¨¡å‹ï¼ˆéœ€è¦é‡æ–°è®­ç»ƒï¼‰")
print("     - ç§»é™¤æ‰€æœ‰ clamp/clip")
print("     - åœ¨ HDR æ•°æ®ä¸Šå¾®è°ƒæˆ–é‡æ–°è®­ç»ƒ")

print("\n" + "=" * 80)
